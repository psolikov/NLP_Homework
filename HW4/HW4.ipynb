{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.4.5)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.13.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line(line):\n",
    "    return list(filter(lambda x: x != ' ',re.split('(\\W)', line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "TRAIN_DATA_PATH = 'train_qa.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv(DATA_PATH + TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['question_id'] != 61603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paragraph_id', 'question_id', 'paragraph', 'question', 'answer'], dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paragraph_unique = train_data[['paragraph_id', 'paragraph']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DICT = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_paragraph_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-1ab9622169b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_paragraph_unique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_paragraph_unique' is not defined"
     ]
    }
   ],
   "source": [
    "words_dict = {}\n",
    "for idp, p in train_paragraph_unique.iterrows():\n",
    "    text = p['paragraph']\n",
    "    text_words = split_line(text)\n",
    "    for word in text_words:\n",
    "        stemmed_word = stemmer.stem(word.lower())\n",
    "        if stemmed_word not in words_dict:\n",
    "            words_dict[stemmed_word] = len(words_dict) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question_unique = train_data['question'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in train_question_unique:\n",
    "    text = p\n",
    "    text_words = split_line(text)\n",
    "    for word in text_words:\n",
    "        stemmed_word = stemmer.stem(word.lower())\n",
    "        if stemmed_word not in words_dict:\n",
    "            words_dict[stemmed_word] = len(words_dict) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict['<dlmtr>'] = len(words_dict) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    text_tokens = [words_dict[stemmer.stem(word.lower())] for word in split_line(text)]\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_len(text):\n",
    "    idx = 0\n",
    "    result = []\n",
    "    for word in split_line(text):\n",
    "        word_len = len(word)\n",
    "        result.append([idx, word_len])\n",
    "        idx += word_len\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_answer(text):\n",
    "    while text[-1] in '.?!':\n",
    "        text = text[:-1]\n",
    "    while text[0] in '.?!':\n",
    "        text = text[1:]\n",
    "    text = text.lstrip().rstrip()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer_in_text(text, answer):\n",
    "    text_sent_tokens = nltk.sent_tokenize(text)\n",
    "    prep_answer = prepare_answer(answer)\n",
    "    for sent in text_sent_tokens:\n",
    "        sent = sent.lower()\n",
    "        idx = sent.find(prep_answer)\n",
    "        if idx != -1:\n",
    "            return sent, idx\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_no_match = 0\n",
    "no_match_ids = []\n",
    "train_extracted_sent = []\n",
    "for idx, r in train_data.iterrows():\n",
    "    paragraph = r['paragraph']\n",
    "    answer = r['answer']\n",
    "    question = r['question']\n",
    "    find_result = find_answer_in_text(paragraph, answer)\n",
    "    if find_result == -1:\n",
    "        cnt_no_match+=1\n",
    "        no_match_ids.append(idx)\n",
    "        continue\n",
    "    sent, answer_idx = find_result\n",
    "    train_extracted_sent.append([sent, question, answer, answer_idx, len(answer)])\n",
    "    \n",
    "cnt_no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['первые упоминания о строении человеческого тела встречаются в древнем египте.',\n",
       " 'Где встречаются первые упоминания о строении человеческого тела?',\n",
       " 'в Древнем Египте',\n",
       " 60,\n",
       " 16]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extracted_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в древнем египте'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extracted_sent[0][0][60:60+16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('первые упоминания о строении человеческого тела встречаются в древнем египте.',\n",
       " 60)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_answer_in_text(train_data['paragraph'][0],train_data['answer'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_for_model(paragraph, question):\n",
    "    paragraph = prepare_text(paragraph)\n",
    "    question = prepare_text(question)\n",
    "    delemiter = [words_dict['<dlmtr>']]\n",
    "    return paragraph + delemiter + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_extracted_sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-3e14919a38fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_extracted_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_extracted_sent' is not defined"
     ]
    }
   ],
   "source": [
    "train_extracted_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = [[prepare_sample_for_model(paragraph, question), idx, idx + answer_len] for \\\n",
    "                  paragraph, question, _, idx, answer_len in train_extracted_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = defaultdict(lambda x: 0, words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new_X = [torch.tensor(x[0]) for x in train_data_new]\n",
    "train_data_new_y = torch.tensor([[x[1], x[2]] for x in train_data_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = len(words_dict) + 1\n",
    "train_data_new_X_padded = pad_sequence(train_data_new_X, batch_first=True, padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_new_X_padded, train_data_new_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_data():\n",
    "    with open(\"train_data_new_X\", 'wb') as f:\n",
    "        pickle.dump(train_data_new_X, f)\n",
    "    with open(\"train_data_new_y\", 'wb') as f:\n",
    "        pickle.dump(train_data_new_y, f)\n",
    "    with open(\"words_dict\", 'wb') as f:\n",
    "        pickle.dump(dict(words_dict), f)\n",
    "        \n",
    "def backup_data2():\n",
    "    with open(\"train\", 'wb') as f:\n",
    "        pickle.dump(train_data_new_X, f)\n",
    "    with open(\"test\", 'wb') as f:\n",
    "        pickle.dump(train_data_new_y, f)\n",
    "    with open(\"words_dict\", 'wb') as f:\n",
    "        pickle.dump(dict(words_dict), f)\n",
    "\n",
    "def load_backup_data():\n",
    "    with open(\"train_data_new_X\", 'rb') as f:\n",
    "        train_data_new_X = pickle.load(f)\n",
    "    with open(\"train_data_new_y\", 'rb') as f:\n",
    "        train_data_new_y = pickle.load(f)\n",
    "    with open(\"words_dict\", 'rb') as f:\n",
    "        words_dict = defaultdict(lambda x: 0, pickle.load(f))\n",
    "    return train_data_new_X, train_data_new_y, words_dict\n",
    "\n",
    "def load_backup_data_2():\n",
    "    with open('train', 'rb') as f:\n",
    "        train_load = pickle.load(f)\n",
    "    with open('test', 'rb') as f:\n",
    "        test_load = pickle.load(f)\n",
    "    with open('words_dict', 'rb') as f:\n",
    "        words_dict = pickle.load(f)\n",
    "    return train_load, test_load, words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup_data2()\n",
    "train_load, test_load, words_dict = load_backup_data_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = defaultdict(lambda x: 0, words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = MAX_DICT + 1\n",
    "emb_dim = 64\n",
    "num_emb = padding_value + 1\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "weight_decay = 0.0001\n",
    "lr = 0.001\n",
    "num_layers = 1\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self, num_emb, emb_dim, hidden_size, num_layers, out_size=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_emb, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, out_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = x\n",
    "        z = self.embedding(z)\n",
    "        z, _ = self.lstm(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = torch.transpose(z, 1, 2)\n",
    "        z = F.log_softmax(z, dim=2)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([508])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_and_label(data, label):\n",
    "    return torch.cat((data, label), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, n_epoch): \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in tqdm.tqdm_notebook(range(n_epoch)):\n",
    "        train_loss_epoch = []\n",
    "        test_loss_epoch = []\n",
    "        for batch in train_loader:\n",
    "            optim.zero_grad()\n",
    "            data = batch[:, :-2]\n",
    "            y = batch[:,-2:]\n",
    "            data = data.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(data.long())\n",
    "            y = y.squeeze(1)\n",
    "            start = y[:,0].reshape(-1)\n",
    "            end = y[:,1].reshape(-1)\n",
    "#             print(start.long().shape, end.shape)\n",
    "#             print(output[:,0].shape, output[:,1].shape)\n",
    "#             print(output[:,0].long(), start)\n",
    "#             print(output[:,1].long(), end)\n",
    "            loss_start = loss_fn(output[:,0], start)\n",
    "            loss_end = loss_fn(output[:,1], end)        \n",
    "#             print(torch.max(output),torch.min(output))\n",
    "#             print(torch.max(start),torch.min(start))\n",
    "#             print(torch.max(end),torch.min(end))\n",
    "#             print(output.type())\n",
    "#             print(start.type())\n",
    "#             print(end.float().type())\n",
    "#             print(torch.FloatTensor(end).type())\n",
    "            loss = (loss_start + loss_end) / 2\n",
    "#             print(output.dtype, start.dtype)\n",
    "#             print(loss)\n",
    "            train_loss_epoch.append(loss.item())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        test_loss_epoch = []\n",
    "        train_loss.append(np.mean(train_loss_epoch))\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                optim.zero_grad()\n",
    "                data = batch[:, :-2]\n",
    "                y = batch[:,-2:]\n",
    "                data = data.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(data.long())\n",
    "                y = y.squeeze(1)\n",
    "                start = y[:,0].reshape(-1)\n",
    "                end = y[:,1].reshape(-1)\n",
    "                loss_start = loss_fn(output[:,0], start)\n",
    "                loss_end = loss_fn(output[:,1], end)        \n",
    "                loss = (loss_start + loss_end) / 2\n",
    "                test_loss_epoch.append(loss.item())\n",
    "            test_loss.append(np.mean(test_loss_epoch))\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(59098)\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(torch.max(x[:,:-2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QAModel(num_emb, emb_dim, hidden_size, num_layers)\n",
    "model = model.float()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87890b2b9d134d558ed6a7a3db95cba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss, test_loss = train_model(model, train_load, val_load, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loss), len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXjV5Z338fc3CySBkED2BQiyL2GRRRS0AiqbdZlauzm1vWbqdMZWfZ620+Vpp9PO1bk6z8w41TrVx7ZWO61tLdpF0AoCsrgDQoAkEmQN2VlCIHvO/fzxOyEhJiGQ5eSc83ld17lIzrl/v3Ofc+mHm+/vvu+fOecQEZHgFxHoDoiISN9QoIuIhAgFuohIiFCgi4iECAW6iEiIiArUGycnJ7ucnJxAvb2ISFDauXNnlXMupbPXAhboOTk57NixI1BvLyISlMzsaFevqeQiIhIiFOgiIiFCgS4iEiICVkMXEbkSTU1NFBcXU19fH+iu9KuYmBiys7OJjo7u8TEKdBEJKsXFxcTHx5OTk4OZBbo7/cI5x8mTJykuLmbcuHE9Pk4lFxEJKvX19SQlJYVsmAOYGUlJSZf9rxAFuogEnVAO81ZX8hmDLtCLymv4/ov5NDS3BLorIiKDStAFevHpOp56/TCvH6wKdFdEJAydOXOGn/zkJ5d93KpVqzhz5kw/9KhN0AX6ognJjIiJYl1eWaC7IiJhqKtAb25u7va4l156icTExP7qFhCEgT4kKoJbpqezPr9MZRcRGXDf+MY3+OCDD5g9ezbz58/n+uuv57bbbmPatGkA3HHHHcydO5fp06fz5JNPXjguJyeHqqoqjhw5wtSpU/nCF77A9OnTueWWW6irq+uTvgXltMXVuRms2VnM9qIqlk1NC3R3RCRAvvfifvJLzvbpOadljuC7H53e5es//OEP2bdvH7t37+a1115j9erV7Nu378L0wqeeeopRo0ZRV1fH/Pnz+djHPkZSUtJF5ygqKuI3v/kNP/3pT7n77rt5/vnnueeee3rd96AboUO7ssve0kB3RUTC3IIFCy6aK/7oo48ya9YsFi5cyPHjxykqKvrQMePGjWP27NkAzJ07lyNHjvRJX4JyhN5adnlln1d2GRoVGeguiUgAdDeSHijDhg278PNrr73Gq6++yptvvklcXBw33nhjp3PJhw4deuHnyMjIPiu5BOUIHWD1zAxqGprZXqTZLiIycOLj46mpqen0terqakaOHElcXByFhYW89dZbA9q3oByhAywa3zrbpVR1dBEZMElJSSxatIgZM2YQGxtLWlpb/qxYsYInnniCqVOnMnnyZBYuXDigfbtkoJtZDLAVGOpvv8Y5990ObYYCvwTmAieBTzjnjvR5b9sZEhXB8unp/EVlFxEZYM8++2ynzw8dOpSXX36509da6+TJycns27fvwvNf/epX+6xfPSm5NABLnXOzgNnACjPr+NfO3wCnnXMTgP8C/q3PetiNVf6yy7YDKruIiFwy0J3nnP/XaP/DdWh2O/CM/+c1wDIbgM0WFo1PJiE2mpc020VEpGcXRc0s0sx2AxXABufc2x2aZAHHAZxzzUA1kNShDWZ2n5ntMLMdlZWVves5/tku09LYkF+uRUYiEvZ6FOjOuRbn3GwgG1hgZjOu5M2cc0865+Y55+alpHR60+rLtlplFxER4DKnLTrnzgCbgRUdXjoBjAYwsyggAe/iaL9bNMEru2iRkYiEu0sGupmlmFmi/+dY4GagsEOzPwP3+n++C9jknOtYZ+8X0ZERLJ+exqv55dQ3qewiIuGrJyP0DGCzmeUB7+LV0Nea2ffN7DZ/m58DSWZ2EPjfwDf6p7udWz0z0yu7aJGRiPSzK90+F+BHP/oRtbW1fdyjNj2Z5ZLnnJvjnJvpnJvhnPu+//l/cs792f9zvXPu4865Cc65Bc65Q/3W405cNz6JxDjNdhGR/jeYAz1oV4q2Fx0ZwfJp6azbW0p9Uwsx0VpkJCL9o/32uTfffDOpqak899xzNDQ0cOedd/K9732P8+fPc/fdd1NcXExLSwvf+c53KC8vp6SkhCVLlpCcnMzmzZv7vG8hEejgLTL63Y7jbCuq4uZp2gpAJCy8/A0o29u350zPhZU/7PLl9tvnrl+/njVr1vDOO+/gnOO2225j69atVFZWkpmZybp16wBvj5eEhAQefvhhNm/eTHJyct/22S9oN+fqqLXssi6vJNBdEZEwsX79etavX8+cOXO4+uqrKSwspKioiNzcXDZs2MDXv/51tm3bRkJCwoD0J2RG6Cq7iIShbkbSA8E5xze/+U3+7u/+7kOv7dq1i5deeolvf/vbLFu2jH/6p3/q9/6EzAgdvEVG5xqa2Xqg96tQRUQ603773OXLl/PUU09x7py3O8qJEyeoqKigpKSEuLg47rnnHr72ta+xa9euDx3bH0JmhA5wbbvZLrdMTw90d0QkBLXfPnflypV8+tOf5tprrwVg+PDh/OpXv+LgwYN87WtfIyIigujoaB5//HEA7rvvPlasWEFmZma/XBS1AVr/8yHz5s1zO3bs6PPzfuP5PF7cU8LO79yssotICCooKGDq1KmB7saA6OyzmtlO59y8ztqHVMkFYFVuBucbW9iisouIhJmQC/RrxycxUouMRCQMhVyge3u7pGtvF5EQFqhS8UC6ks8YcoEO3mwXlV1EQlNMTAwnT54M6VB3znHy5EliYmIu67iQmuXS6tqrvLLLurxSlmu2i0hIyc7Opri4mL64Sc5gFhMTQ3Z29mUdE5KBHhUZwYoZ6fx5d4kWGYmEmOjoaMaNGxfobgxKIVlygbbZLq+9H9p/i4uItArZQG8tu2i2i4iEi5AN9Nayy6sFmu0iIuEhZAMdYHVuJrUqu4hImAjpQF941ShGDRuiG0iLSFgI6UCP8i8y2qiyi4iEgZAOdIDVuRn+sktFoLsiItKvQj7Q28ouZYHuiohIvwr5QFfZRUTCRcgHOsCtM1V2EZHQFxaBfs24USQNG8LaPM12EZHQdclAN7PRZrbZzPLNbL+ZPdhJmwQze9HM9vjbfL5/untloiIjWD4jnU2FFdQ1quwiIqGpJyP0ZuArzrlpwELgfjOb1qHN/UC+c24WcCPwn2Y2pE972ku3araLiIS4Swa6c67UObfL/3MNUABkdWwGxJuZAcOBU3h/EQwaC/xlFy0yEpFQdVk1dDPLAeYAb3d46TFgKlAC7AUedM75Ojn+PjPbYWY7Bnov49a9XTYWqOwiIqGpx4FuZsOB54GHnHNnO7y8HNgNZAKzgcfMbETHczjnnnTOzXPOzUtJSelFt6/M6twM6ppa2Kyyi4iEoB4FuplF44X5r51zL3TS5PPAC85zEDgMTOm7bvaNBeNGkTxcZRcRCU09meViwM+BAufcw100OwYs87dPAyYDh/qqk32ldZHRJpVdRCQE9WSEvgj4a2Cpme32P1aZ2RfN7Iv+Nv8CXGdme4GNwNedc1X91OdeWT1TZRcRCU2XvKeoc247YJdoUwLc0led6k/XjEvyyi55pazKzQh0d0RE+kxYrBRtLzLCWOFfZFTbOKhmVoqI9ErYBTp4N5Cua2phc6HuZCQioSMsA7217KIbSItIKAnLQG8tu2wsLFfZRURCRlgGOng3kK5v8qnsIiIhI2wD3VtkNJR1e0sC3RURkT4RtoEeGWGs1GwXEQkhYRvo4M12qW/ysalQi4xEJPiFdaC3ll0020VEQkFYB7rKLiISSsI60MHb20VlFxEJBWEf6PNz/LNddANpEQlyYR/okRHGqtx0Nr9fwfkGlV1EJHiFfaCDZruISGhQoOOVXVLiNdtFRIKbAh1/2cU/20VlFxEJVgp0v1W5GTQ0+9iosouIBCkFut+8nFGkxg/lJc12EZEgpUD3a11kpNkuIhKsFOjtrJ6ZqbKLiAQtBXo788aOJDV+KOvytKWuiAQfBXo7ERHGqtwMXnu/knMqu4hIkFGgd3BhtktBeaC7IiJyWS4Z6GY22sw2m1m+me03swe7aHejme32t9nS910dGK1lFy0yEpFgE9WDNs3AV5xzu8wsHthpZhucc/mtDcwsEfgJsMI5d8zMUvupv/2utezy7DvHONfQzPChPfmKREQC75IjdOdcqXNul//nGqAAyOrQ7NPAC865Y/52QT1NZPXMDBpVdhGRIHNZNXQzywHmAG93eGkSMNLMXjOznWb22S6Ov8/MdpjZjsrKyivp74CYO2YkaSO0pa6IBJceB7qZDQeeBx5yzp3t8HIUMBdYDSwHvmNmkzqewzn3pHNunnNuXkpKSi+63b8iIoyVMzJ47YBmu4hI8OhRoJtZNF6Y/9o590InTYqBV5xz551zVcBWYFbfdXPgqewiIsGmJ7NcDPg5UOCce7iLZn8CFptZlJnFAdfg1dqDlsouIhJsejKFYxHw18BeM9vtf+5bwBgA59wTzrkCM/sLkAf4gJ855/b1R4cHSmvZ5dl3jlFT30R8THSguyQi0q1LBrpzbjtgPWj378C/90WnBotbZ2bw9BtH2FRYwe2zO07sEREZXLRStBtXjxlJ+ogY1qrsIiJBQIHejYgIY2VuOlsOVFJT3xTo7oiIdEuBfgmrc1tnuwT1WikRCQMK9EtoLbus094uIjLIKdAv4ULZ5X2VXURkcFOg98CtMzNobPHxqhYZicggpkDvgTmj/WWXvLJAd0VEpEvBF+gtTXD0jQF9y9YtdbceqOSsyi4iMkgFX6Dv+S38YiX86mNQNnCLUVf7yy7a20VEBqvgC/Tcj8PN34fid+GJxfCHL8KZ4/3+tnNGJ5KREKO9XURk0Aq+QI+OgUUPwoN74Lovw74X4MdzYf23ofZUv71tW9mlSmUXERmUgi/QW8WOhFv+Bb68E2Z8DN54DB6dDdt/BE11/fKWq3L9s13yVXYRkcEneAO9VeJouPNx+OJ2yF4Ar34XfjwP3vs1+Fr69K3mjE4kMyFGN5AWkUEp+AO9VfoMuGcN3PsiDE+FP/0DPHE9HFgPzvXJW3iLjFR2EZHBKXQCvdW4G+ALm+CuX0BTLTz7cXjmo3BiZ5+cvnW2i8ouIjLYhF6gA5jBjL+C+9+Blf8OFQXw06Xw3L1w8oNenbq17KLZLiIy2IRmoLeKGgLX3AcPvAc3/CMUrYf/XgDrvgrnKq/olGbebJdtRVVU16nsIiKDR2gHequYEbD0/8ADu+Hqz8KOp7wZMa/9GzScu+zTrVLZRUQGofAI9FbxaXDrf8H9b8P4JfDav8Kjc+Ddn3lbCvTQnNGJZCXGsjavpB87KyJyecIr0FslT4RP/Ar+ZgMkjYd1X4GfLIT8P/VoRoyZcdvsTDa/X8mnnnyLtw6dHIBOi4h0LzwDvdXoBfD5l+FTv4WIKHjus/Dzm3u0+ddDN03k26uncrDyHJ988i3u/n9v8sbBKlwfTZEUEblcFqgAmjdvntuxY0dA3rtTLc2w51nY/K9QUwqTVsJN/wypU7o9rL6phd+8c4zHX/uAipoG5ueM5MFlk1g0IQkzG5Cui0j4MLOdzrl5nb6mQO+gsRbeftzbQqDxHMz+DCz5FozI7Paw+qYWfvfucR5/7QPKztYzd+xIHlg2kRsmJivYRaTPKNCvxPmTsO0/4J2feuWYhX8Pix+CmIRuD2tobuG5HcU8vvkgJdX1zB6dyIM3TeTGSSkKdhHptV4FupmNBn4JpAEOeNI590gXbecDbwKfdM6t6e68gz7QW50+Apt+AHuf8zYEu+FrMP9vIWpot4c1NLewZmcxP9n8ASfO1DErO4EHlk1k6ZRUBbuIXLHeBnoGkOGc22Vm8cBO4A7nXH6HdpHABqAeeCpkAr1V6R7Y8F04tBkSx8DS78CMuyCi++vKjc0+XthVzGObD1J8uo4ZWSN4YOlEbp6WpmAXkcvWpyUXM/sT8JhzbkOH5x8CmoD5wNqQC/RWH2zygr0sD1Knw/y/8W66ETOi28OaWnz84b0T/Pfmgxw9Wcu0jBE8sGwit0xLIyJCwS4iPdNngW5mOcBWYIZz7my757OAZ4ElwFN0Eehmdh9wH8CYMWPmHj16tOefYjDx+WDfGnj9ESjfB9Fx3p7scz8PWVd7e8l0obnFxx93l/DYpiKOnKxlSno8DyybyIrp6Qp2EbmkPgl0MxsObAF+4Jx7ocNrvwf+0zn3lpk9TSiP0NtzDk7sgp2/gH3Pe7s7puXC3Hth5t3dXkBtbvHxYl4JP954kENV55mcFs+Xl01g1YwMBbuIdKnXgW5m0cBa4BXn3MOdvH4YaE2hZKAWuM8598euzhkSgd5e/VnY+3sv3Mv2QlSsf9T+Ocie1+WovcXnWJtXwqMbi/ig8jwTU4fzpaUTuHVmJpEKdhHpoLcXRQ14BjjlnHuoB2/2NOEyQu+Mc1DyHux8GvaugabzXq197ue8UXtsYqeHtfgc6/aW8uONRRRVnGN8yjC+vHQiH52lYBeRNr0N9MXANmAv4PM//S1gDIBz7okO7Z8mnAO9vYYaL9R3Pg2lu71R+/Q7vXAfvaDTUbvP53h5XxmPbizi/fIarkoexpeWTuC2WZlERYb3Tg0iooVFg0PJe7DzGa8s03gOUqZ6wT7rE9789g58Psf6/DIe2XiQgtKz5CTFcf+SCdwxJ4toBbtI2FKgDyYN57wLqDufhpJdEBUD0+7wwn3Mwg+N2n0+x4aCch7dWMT+krOMGRXH/UvG81dXZyvYRcKQAn2wKt3jjdrznoPGGkie7B+1fxLiRl3U1DnHxoIKHtlYxN4T1WSPjOX+JRP42NXZDIlSsIuECwX6YNd4Hva94I3aT+yAyKEw7XYv3Mded9Go3TnH5vcreOTVIvYUV5OVGMu9143lpqlpXJUyPGAfQUQGhgI9mJTt9Y/afwcNZyFpon/U/ikYlnShmXOOLQcqeXRjEbuOnQEgJymOpVPSWDollQXjRmnkLhKCFOjBqLEW9v/BG7UXvwORQ2DqbV645yy+aNR+/FQtmwor2FRYwZuHTtLY7GPYkEgWT0xm6ZRUlkxOJXVETMA+ioj0HQV6sCvf7x+1/xbqq2HUeC/YZ38ahiVf1LS2sZk3Dp5k0/sVbC6soLS6HoAZWSNYOjmVJVNSmZWdqNWoIkFKgR4qmuq8+57ufBqOvQkR0TD1Vm/kPmocjMy5aAqkc47Csho2FXrhvuvYaXwOkocP4SOTUlk6JZXrJyUzIiY6YB9JRC6PAj0UVRTCrmdg97NQf6bt+ZgESBzrhftI/5+JOTAyh9PRaWw5dJZNhRVsOVBJdV0TURHGvJyRLJ3iBfz4lOHa1ldkEFOgh7Kmeqg64N2I48xR78/TR9t+b2ls19i8W+mNzMGXMIbSiHTeqxnBpvI4tlUNp5JERo+KY+nkVJZOTeOacaOIiY4MzOcSkU4p0MOVzwfnyj4c8qePeI+a0ouaN0cMpSIyjQONSRxpSaEsIo3h6RO4auJ05s6eQ1pKcidvIiIDqbtAjxrozsgAiojwRuQjMr357B011cOZYxdCPur0ETJPHyH91BEWn3qdqObzUIH3eB2qbQS1cdkMTb2KxMyJRIzK8Zd0xkJCNkSqFi8SSAr0cBYdAymTvEc7EUCEc1B3Gnf6CKVHCjl2MJ+asoPE1hwnu+Zd4g+/TAQtbQdZJCRNgMw5kDnb+zM9F4YMG9jPJBLGVHKRy1Jd28SWokq2FJRQ8H4hCQ0ljI2oZEHCWeYMPUF2XSHRdZVeY4uA5EleuGe0D/m4wH4IkSCmGrr0ixafY/fxM2z2L2rKL/XuSjgxtoa/Sq9g8bATTGguIrZyL5yv8A6yCEiZ0hbwmbMhbYZCXqSHFOgyICprGnjjgyq2FVWxvaiKsrPeoqaxo2JZlQM3J5YwjUPEVOR5+8Ofbx3JR3oh31qqyZgN6TMgOjZwH0ZkkFKgy4BzzvFB5bkL4f7WoZOcb2whwmBmdiKLxyexNKuZ3IjDRJfv8faLL9kNtVXeCSwSUqf6R/L+oE+b4dX9RcKYAl0CrqnFx3vHzrD9YBXbiyrZU1xNi88RNySSa8aNYvHEFK6fkMTEmDNY6R4v3Eve80bytSe9k0REeTcGyfSHfMYcSJuukJewokCXQedsfRNvfnCS7UVVbD9YxeGq8wCkjRjKognJXD8xmUXjk0mNHwrVx72AL93dNpKvO+WdKCLKG8lfuPA62wt91eQlRCnQZdArPl3L9qIqth2s4o2DVZyubQJgclo8iycms3hiMteMG0XckCjvRtxnjvkDvt1Ivu60/2zmbXuQMhVSJnv1+dQp3owbTaOUIKdAl6Di8znyS8969feDlbx75DSNzT6GREZw9dhErp+YwuIJyczISiCydddI57wFUqV7oKIAKguh8n2oKgJfk//MBoljvIBPmeyN7FMme3eKGqqbg0hwUKBLUKtrbOHdI6fYftCbQVPgnx6ZEBvNoglJLJ7gBfyYpE7KLC1NcOowVBZ4AV9Z6G1sdrLo4n1uEsb4R/OtQe8P/aHxA/QpRXpGgS4hpavpkWNGxbF4YjK3TEtj0YTk7m+i3dLs7WdT2W40X1HobXTW0tDWbkT2xaP51qCPSejfDynSBQW6hCxveuR5thdVsv1gFW9+4E2PTIiNZsX0dFbPzODa8Undh3t7vhZ/0Be2C/oCL+ib69vaxWd2CHr/n7GJ/fI5RVr1KtDNbDTwSyANcMCTzrlHOrT5DPB1wIAa4O+dc3u6O68CXfpDQ3ML2w5UsW5vKRvyyznX0MzIuGiWt4b7VUlE9TTc2/O1eBdiOwv6ptq2dsPT2y7ADk+FuCT/I7nt59iREKltlOTK9DbQM4AM59wuM4sHdgJ3OOfy27W5Dihwzp02s5XAPzvnrunuvAp06W/1TS1sPVDJur2lvJpfzvnGFkYNG8Ly6encOjODa8aNurJwb8/n86ZVdgz6kwe9m3x3JSaxXdi3PkZ18pz/+ZhEb/dMCXt9WnIxsz8BjznnNnTx+khgn3Muq7vzKNBlINU3tbDlQCXr8kp5taCc2sYWkoYNYcUMb+R+zbikthkzfaW5AWpPeQujLnp09VzVxWWd9iwCYkf1IPzbvTY0/qKbiUto6LNAN7McYCswwznX6fDDzL4KTHHO/W1351KgS6DUNbaw5UAFa/NK2VhQQV1TC8nDh7LSH+7zc0b1fbj3VGNtD8K/w/MXpmV2EBHt3UR8RJa3X31CNiSMhoSstp/jkhT6QaZPAt3MhgNbgB84517oos0S4CfAYufcyU5evw+4D2DMmDFzjx492rNPINJP6hpb2Px+BevyStlYWE59k4+U+KGsmpHO6pmZzBs7kohAhXtPOAcNNV2H/7kKOFsM1cVQfQKa6y4+PirGC/cRWf6wz774MSIrOFfdtn4vdacvfgxLgez5Qb1dRK8D3cyigbXAK865h7toMxP4A7DSOXfgUufUCF0Gm9rGZjYVeuG+qbCChmYfqfFDWZWbweqZGcwdM8jD/VKc80K/+rg/4Iu9n8+eaPu9pgxv7kM7cUltI/oPjfazvYu/Ef1071mfz7sWcSGUT0HdmQ8HdWcPX3Pn54yKgTELYdxH4KqPeFtG9Ff/+0FvL4oa8Axwyjn3UBdtxgCbgM86597oSacU6DKYnW9oZmNhBevyStj8fiWNzT7SR8SwMte7oDpndJCHe1eaG6GmxBvNtwb+hfD3PxprLj4mIsq7zWH7EX7HEf+QYVBf3XX41p7q/Pn6M+B8Xfd3SLw3ayg20f+n/xE36uLfY0d6F5bPHIPDW+DQFqjY750jJgFyrodxN3ghnzJ5UJehehvoi4FtwF6g9Zv9FjAGwDn3hJn9DPgY0FpDae7qDVsp0CVYnGtoZmNBOWvzStnyfiWNLT4yEmIujNznjE7EBnEA9Ln66otH+NUnLg78syfAtVz6PO0NTbg4lDsL5Iseo7z2vbmP7bkKOLy1LeDP+ONreLoX7ld9xAv4xNFX/h79QAuLRPpITX0TGwu8C6pbD3jhnpUYy6pcr+Y+KzshvMK9M74Wr3Rz9kTbCL/xfBehPNIbIQ+Gefmnj3gBf2iLF/KtN2AZdZUX7K0j+GFJAe2mAl2kH5ytb+LV/HLW5ZWytaiSphZHVmIst87MYFVuBjMV7sHLOW89Qevo/ejrbesK0nLbRu9jrxvwjd0U6CL9rLquiQ355azLK2FbURXNPkdmQgy3TE/nlulpLMjpg0VMEjgtzd42zYf9o/djb3t7/kREQdY8f8Df4M2giRrar11RoIsMoDO1jWzIL+eV/eVsK6qkodnHyLholk1NY/n0dK6fmExMdPDMqpBONNXB8bfbyjMl73kXb6NiYey1bTNo0mf2+QwaBbpIgNQ2NrPl/Upe2V/GxsIKauqbiRsSyUcmpbB8ejpLpqSSENuLC3syONSd8coyrQFfWeg9H5MI46731+A/AskTez2DRoEuMgg0Nvt4+/BJXtlfxvr95VTUNBAVYVw7PskrzUxLI21E8C54kXZqyv0zaF6DQ1uh+pj3fHymV5qZeTdMWHZFp1agiwwyPp9jd/GZC+Heek/VOWMSWT49neXT0xmXrNvlhQTn4PThttH74a2w8O/hhq9d0ekU6CKDmHOOoopzvLKvjPX55ew9UQ3ApLThLJ+ezi3T0pmRNUIzZkKFz+fdLesKtx9QoIsEkRNn6li/v4xX9pfxzuFT+BxkJcZy8zTvour8nJGaMRPGFOgiQerU+UZeLShn/f4ythZV0eifMXOTf8bMYs2YCTsKdJEQcL6hma0HNGMm3HUX6INgva2I9MSwoVGszM1gZW4Gjc0+3jrknzGTX87L+8qIjjQWXpXkr7unkaoZM2FHI3SRIOfzOd47fuZC3f3IyVrMYM5ob8bMqtwMRo8Kwj3NpVMquYiEifYzZl7JL2PfCW//kVmjE/mof4+ZzMTYAPdSekOBLhKmjp+qZW1eKev2llwI97ljR17YQEwLmYKPAl1EOFx1nnV5JazNK6WwrAYzmJ8ziltnZrByRgYp8f27qZT0DQW6iFzkYMU51uWVsjavhKKKc0QYLLwqidUzM1gxPZ2k4Qr3wUqBLiJdOlBew9o93sj9UNV5IiOM68YncevMDJZPTycxbkiguyjtKNBF5JKccxSU1qWgrjAAAAk/SURBVLBurxfuR0/WEhVhLJ6YzOrcDG6Znq557oOAAl1ELotzjn0nzrJ2bwnr8kopPl1HdKRxw8QUbp2VwU1T04iPUbgHggJdRK6Yc449xdWs3VPCur2llFbXMyQqghsnpXDrrEyWTUll2FCtURwoCnQR6RPeIqbTvLinlJf2llJR00BMdARLp6SyOjeTpVNSiR2ivWX6kwJdRPqcz+d498gp1u0t5aW9ZVSdayA2OpJlU1O5dWYmN05O0cZh/UCBLiL9qsXnePvwSdbmlfKXfWWcOt/I8KFR3OQP9+snJTM0SuHeFxToIjJgmlt8vHnoJGv3lPKX/WVU1zUxIiaK22Zn8vG5o5mZnaCbdfRCrwLdzEYDvwTSAAc86Zx7pEMbAx4BVgG1wOecc7u6O68CXST0NbX42H6wij++d4K/7CujodnHxNTh3DU3mzvnZGlHyCvQ20DPADKcc7vMLB7YCdzhnMtv12YV8GW8QL8GeMQ5d01351Wgi4SXs/VNrMsr5fc7jrPr2BkiDD4yKYWPzxvNsqmpKsn0UK/2Q3fOlQKl/p9rzKwAyALy2zW7Hfil8/52eMvMEs0sw3+siAgjYqL51IIxfGrBGD6oPMfzO4t5YdcJ/uHXu0iIjeb22ZncNTeb3CyVZK7UZdXQzSwH2ArMcM6dbff8WuCHzrnt/t83Al93zu3ocPx9wH0AY8aMmXv06NHe9l9EgliLz/H6wSp+v7OYV/aX0djsY3JaPHfNzeb2OZmkxqsk01Gf3LHIzIYDzwMPtQ/zy+GcexJ4ErySy5WcQ0RCR2SEccOkFG6YlEJ1XRNr80pYs7OYH7xUwA//UsiNk1K4a242S1WS6ZEeBbqZReOF+a+dcy900uQEMLrd79n+50REeiQhNprPXDOWz1wzloMV53h+VzEv7CpmY2EFiXHR3D4rk4/PG830zBEqyXShJxdFDXgGOOWce6iLNquBL9F2UfRR59yC7s6ri6IiciktPse2okrW7CxmfX45jc0+pqT7SzKzs8JyD/feznJZDGwD9gI+/9PfAsYAOOee8If+Y8AKvGmLn+9YP+9IgS4il6O6tokX/SWZ3cfPEBlhLJnsL8lMSWNIVESguzggtLBIREJKUXkNa3YV84ddJ6ioaWBkXDS3z87irrnZIV+SUaCLSEhqbvGx7WAVa3YUsyG/nMaWtpLMHXOySA7BOy8p0EUk5J2pbeTFPV5JZk9xNVERxpIpqdw1N5slk1NDpiSjQBeRsHKgvMZbuPTeCSprGhg1bAi3z87kk/PHMDk9PtDd6xUFuoiEpeYWH1v9s2Reza+gscXHtVcl8blFOdw0NY3IiOCrtSvQRSTsnT7fyO92HOd/3jzKiTN1ZCXG8tlrx/KJ+aOD6kbYCnQREb/mFh+vFpTzi9eP8PbhU8RER3DnnGw+d11OUJRjFOgiIp0oKD3LM28c4Q/vnaChOTjKMQp0EZFunD7fyG/fPc7/vHmEkup6skf6yzHzxpAQFx3o7l1EgS4i0gPBUI5RoIuIXKb8Eq8c88fdXjnmuvFJ3Htd4MsxCnQRkSs02MoxCnQRkV5qbvGxIb+cX7xxhHcOnyI2OpI7r87ic9flMClt4MoxCnQRkT7UWTnmc9flsGwAyjEKdBGRfnDqfCO/ffcYv3rz6ICVYxToIiL9aCDLMQp0EZEB0rEcs2hCEvde23flGAW6iMgA66wcc++1Odw9b3SvyjEKdBGRAOmsHPOVWybxt9dfdUXn6y7Qo3rVUxER6VZUZAQrczNYmZvB/pJqnnnjCJmJsf3zXv1yVhER+ZDpmQn837tm9dv5Q+OeTCIiokAXEQkVCnQRkRChQBcRCRGXDHQze8rMKsxsXxevJ5jZi2a2x8z2m9nn+76bIiJyKT0ZoT8NrOjm9fuBfOfcLOBG4D/NLHjuuCoiEiIuGejOua3Aqe6aAPFmZsBwf9vmvumeiIj0VF/U0B8DpgIlwF7gQeecr7OGZnafme0wsx2VlZV98NYiItKqLxYWLQd2A0uB8cAGM9vmnDvbsaFz7kngSQAzqzSzo1f4nslA1RUeG4r0fVxM30cbfRcXC4XvY2xXL/RFoH8e+KHzNoU5aGaHgSnAO90d5JxLudI3NLMdXe1lEI70fVxM30cbfRcXC/Xvoy9KLseAZQBmlgZMBg71wXlFROQyXHKEbma/wZu9kmxmxcB3gWgA59wTwL8AT5vZXsCArzvngv2fNCIiQeeSge6c+9QlXi8BbumzHvXMkwP8foOdvo+L6ftoo+/iYiH9fQRsP3QREelbWvovIhIiFOgiIiEi6ALdzFaY2ftmdtDMvhHo/gSSmY02s81mlu/fR+fBQPcp0Mws0szeM7O1ge5LoJlZopmtMbNCMysws2sD3adAMbP/5f9/ZJ+Z/cbMYgLdp/4QVIFuZpHAfwMrgWnAp8xsWmB7FVDNwFecc9OAhcD9Yf59ADwIFAS6E4PEI8BfnHNTgFmE6fdiZlnAA8A859wMIBL4ZGB71T+CKtCBBcBB59wh51wj8Fvg9gD3KWCcc6XOuV3+n2vw/ofNCmyvAsfMsoHVwM8C3ZdAM7ME4Abg5wDOuUbn3JnA9iqgooBYM4sC4vC2Kgk5wRboWcDxdr8XE8YB1p6Z5QBzgLcD25OA+hHwj0CnewmFmXFAJfALfwnqZ2Y2LNCdCgTn3AngP/AWQZYC1c659YHtVf8ItkCXTpjZcOB54KHO9tAJB2Z2K1DhnNsZ6L4MElHA1cDjzrk5wHkgLK85mdlIvH/JjwMygWFmdk9ge9U/gi3QTwCj2/2e7X8ubJlZNF6Y/9o590Kg+xNAi4DbzOwIXiluqZn9KrBdCqhioNg51/ovtjV4AR+ObgIOO+cqnXNNwAvAdQHuU78ItkB/F5hoZuP8N9H4JPDnAPcpYPx70P8cKHDOPRzo/gSSc+6bzrls51wO3n8Xm5xzITkK6wnnXBlw3Mwm+59aBuQHsEuBdAxYaGZx/v9nlhGiF4j7YrfFAeOcazazLwGv4F2pfso5tz/A3QqkRcBfA3vNbLf/uW85514KYJ9k8Pgy8Gv/4OcQ3s6oYcc597aZrQF24c0Me48Q3QJAS/9FREJEsJVcRESkCwp0EZEQoUAXEQkRCnQRkRChQBcRCREKdBGREKFAFxEJEf8fV79IZWct/VUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_sent(text, question):\n",
    "    sent_tokens = nltk.sent_tokenize(text)\n",
    "    minimum = 10000\n",
    "    min_token = None\n",
    "    vect = TfidfVectorizer()\n",
    "    res = vect.fit_transform(sent_tokens + [text])\n",
    "    for idx, token in enumerate(sent_tokens):\n",
    "        dist = cosine(res[idx].todense(), res[q_idx].todense())\n",
    "        if dist < minimum:\n",
    "            minimum = dist\n",
    "            min_token = token\n",
    "    return min_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad q 61603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad = 0\n",
    "# for idx, p in train_data.iterrows():\n",
    "#     paragraph = p['paragraph'].lower()\n",
    "#     answer = p['answer']\n",
    "#     answer = prepare_answer(answer)\n",
    "#     if answer not in paragraph:\n",
    "#         print(p['paragraph'], '\\n', p['answer'], '\\n\\n\\n\\n', p['question'])\n",
    "#         print(p['paragraph'] == p['answer'])\n",
    "#         print(p['question_id'])\n",
    "#         bad += 1\n",
    "# print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_index_of_last_token_start(text):\n",
    "#     split_text = split_line(text)\n",
    "#     idx = 0\n",
    "#     for i in range(len(split_text) - 1):\n",
    "#         idx += len(split_text[i])\n",
    "#     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_answer = []\n",
    "# for idx, p in train_data.iterrows():\n",
    "#     paragraph = p['paragraph'].lower()\n",
    "#     answer = p['answer']\n",
    "#     answer = prepare_answer(answer)\n",
    "#     answer_start = paragraph.index(answer)\n",
    "#     answer_end = answer_start + get_index_of_last_token_start(answer) \n",
    "#     data_answer.append([answer_start, answer_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped_data = list(zip(data_paragraph, data_question, data_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_paragraph_id_and_len = [get_id_and_len(text) for text in train_data['paragraph'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len_text = 0\n",
    "# for idx, p in train_data.iterrows():\n",
    "#     text = p['paragraph']\n",
    "#     max_len_text = max(max_len_text, len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_len = max_len_text * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(words_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
